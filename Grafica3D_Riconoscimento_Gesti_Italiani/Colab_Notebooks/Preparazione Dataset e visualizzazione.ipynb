{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1x2FRiYa5F0aFQDQK58FWWNswqFNiP6Ql","timestamp":1751743582213},{"file_id":"1H0bEi0vqOWe9TzColWihqdcCseYooLEv","timestamp":1751743173046}],"gpuType":"T4","collapsed_sections":["iLU0J2u6cZRj","zNNtD3v3Hc0X","YkCqxsGz8lSd"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Collegamento a Drive e Installazione librerie"],"metadata":{"id":"iLU0J2u6cZRj"}},{"cell_type":"code","source":["# 1. COLLEGA GOOGLE DRIVE\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"CBDZOuzmmAUR","executionInfo":{"status":"ok","timestamp":1751744089336,"user_tz":-120,"elapsed":18541,"user":{"displayName":"Andrea Mamoli","userId":"04737477089498372732"}},"outputId":"7ca94255-ab4e-49aa-ffb1-8f0e540646ac","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# 2. INSTALLA LE DIPENDENZE COMPATIBILI\n","!pip uninstall -y mediapipe protobuf\n","\n","# 2. Installa protobuf version\n","!pip install protobuf==3.20.3\n","\n","# 3. Installa mediapipe\n","!pip install mediapipe==0.10.8"],"metadata":{"id":"1BUcgIddjPtX","collapsed":true,"colab":{"base_uri":"https://localhost:8080/","height":855},"executionInfo":{"status":"ok","timestamp":1751743658765,"user_tz":-120,"elapsed":26833,"user":{"displayName":"Andrea Mamoli","userId":"04737477089498372732"}},"outputId":"a3fbca87-9e20-48ce-d333-c906f0c66d85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping mediapipe as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: protobuf 5.29.5\n","Uninstalling protobuf-5.29.5:\n","  Successfully uninstalled protobuf-5.29.5\n","Collecting protobuf==3.20.3\n","  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n","Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: protobuf\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n","grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n","tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-3.20.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"4e767b84b4b843fc90e7002c7c819af0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting mediapipe==0.10.8\n","  Downloading mediapipe-0.10.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.8) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.8) (25.3.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.8) (25.2.10)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.8) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.8) (2.0.2)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.8) (4.11.0.86)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.8) (3.20.3)\n","Collecting sounddevice>=0.4.4 (from mediapipe==0.10.8)\n","  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.8) (1.17.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.8) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.8) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.8) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.8) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.8) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.8) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.8) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.8) (2.9.0.post0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.8) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.8) (1.17.0)\n","Downloading mediapipe-0.10.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n","Installing collected packages: sounddevice, mediapipe\n","Successfully installed mediapipe-0.10.8 sounddevice-0.5.2\n"]}]},{"cell_type":"markdown","source":["# Elaborazione Depth Map e posizionamento Landmarks"],"metadata":{"id":"zNNtD3v3Hc0X"}},{"cell_type":"code","source":["# 3. SCARICA IL MODELLO DI RILEVAMENTO MANI\n","!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\n","\n","# 4. ESEGUI IL CODICE DI ESTRAZIONE LANDMARK\n","import os\n","import cv2\n","import csv\n","import numpy as np\n","import mediapipe as mp\n","from mediapipe.tasks import python\n","from mediapipe.tasks.python import vision\n","import pandas as pd\n","import plotly.graph_objects as go\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","from scipy.ndimage import binary_fill_holes\n","\n","# ---------------- DEPTH MAP FUNZIONI ----------------\n","\n","def load_raw_depth_map(filename, width=640, height=480):\n","    with open(filename, 'rb') as f:\n","        raw_data = np.fromfile(f, dtype=np.uint16, count=width * height)\n","        if raw_data.size != width * height:\n","            raise ValueError(\"Dimensioni del file non corrispondono a quelle attese.\")\n","        depth_map = raw_data.reshape((height, width))\n","    return depth_map\n","\n","def fill_pixel_depth_image(img, i, j):\n","    h, w = img.shape\n","    neighbors = []\n","    for di in [-1, 0, 1]:\n","        for dj in [-1, 0, 1]:\n","            if di == 0 and dj == 0:\n","                continue\n","            ni, nj = i + di, j + dj\n","            if 0 <= ni < h and 0 <= nj < w:\n","                val = img[ni, nj]\n","                if 0 < val < 65535:\n","                    neighbors.append(val)\n","    if neighbors:\n","        img[i, j] = np.mean(neighbors)\n","\n","def process_depth_map(depth_map):\n","    BW = depth_map > 0\n","    BW_filled = binary_fill_holes(BW)\n","    mask = BW_filled.astype(np.uint8) - BW.astype(np.uint8)\n","    h, w = depth_map.shape\n","    for i in range(1, h - 1):\n","        for j in range(1, w - 1):\n","            if mask[i, j]:\n","                fill_pixel_depth_image(depth_map, i, j)\n","    return depth_map\n","\n","# ---------------- PARAMETRI ----------------\n","\n","dataset_path = '/content/drive/MyDrive/GRUPPO_14/dataset'\n","image_width, image_height = 640, 480\n","selected_ids = list(range(21))  # 21 punti della mano\n","\n","# ---------------- INIZIALIZZA MEDIAPIPE ----------------\n","\n","model_path = 'hand_landmarker.task'\n","base_options = python.BaseOptions(model_asset_path=model_path)\n","options = vision.HandLandmarkerOptions(base_options=base_options, num_hands=1)\n","detector = vision.HandLandmarker.create_from_options(options)\n","\n","# ---------------- ELABORA IMMAGINI + DEPTH CORRISPONDENTE ----------------\n","z_depth_list = []\n","\n","for subdir, dirs, files in os.walk(dataset_path):\n","    for file in files:\n","        if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n","            z_depth_list = []\n","            image_path = os.path.join(subdir, file)\n","            image_name_wo_ext = os.path.splitext(file)[0]\n","\n","            # Estrai prefisso:\n","            if \"_Color\" in image_name_wo_ext:\n","                prefix = image_name_wo_ext.split(\"_Color\")[0]\n","            else:\n","                print(f\"Immagine {file} non segue il formato *_Color.*\")\n","                continue\n","\n","            # Costruisci nome del file depth corrispondente\n","            depth_filename = os.path.join(subdir, prefix + '_Depth.raw')\n","            if not os.path.exists(depth_filename):\n","                print(f\"Depth map non trovata per {file} → {depth_filename}\")\n","                continue\n","\n","            # Carica e processa depth map\n","            depth_map = load_raw_depth_map(depth_filename)\n","            filled_depth_map = process_depth_map(depth_map.copy())\n","\n","            # Rilevamento landmark\n","            mp_image = mp.Image.create_from_file(image_path)\n","            result = detector.detect(mp_image)\n","\n","            if not result.hand_landmarks:\n","                print(f\"Nessuna mano trovata in {image_path}\")\n","                continue\n","\n","            landmarks = result.hand_landmarks[0]\n","            output_csv = os.path.join(subdir, prefix + '_landmarks_with_depth.csv')\n","            with open(output_csv, mode='w', newline='') as f:\n","                writer = csv.writer(f)\n","                writer.writerow(['id', 'x_pixel', 'y_pixel', 'z_normalized', 'z_depth'])\n","\n","                for i in selected_ids:\n","                    lm = landmarks[i]\n","                    x_pixel = round(lm.x * (image_width - 1))\n","                    y_pixel = round(lm.y * (image_height - 1))\n","\n","                    if 0 <= y_pixel < filled_depth_map.shape[0] and 0 <= x_pixel < filled_depth_map.shape[1]:\n","                        z_depth = filled_depth_map[y_pixel, x_pixel]\n","                    else:\n","                        z_depth = -1  # fuori immagine\n","\n","                    z_depth_list.append(z_depth)\n","                    writer.writerow([i, x_pixel, y_pixel, lm.z, z_depth])\n","\n","                # Verifica se tutti i landmark hanno z = -1 → plottiamo la depth map\n","                if all(z == -1 for z in z_depth_list):\n","                  print(f\"ATTENZIONE: tutti i landmark per il frame {file} sono fuori dalla depth map\")\n","\n","\n","\n","            print(f\"Salvato: {output_csv}\")\n"],"metadata":{"id":"z39Kqb-kN8p9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creazione Dataset completo con coordinate e calcolo distanze"],"metadata":{"id":"WFoGllG1sMlH"}},{"cell_type":"code","source":["# 5. ACCORPA TUTTI I CSV IN UN UNICO FILE\n","\n","# Lista per accogliere tutti i dati\n","all_data = []\n","\n","# Scorri nuovamente tutte le cartelle per cercare i file *_landmarks.csv\n","for subdir, dirs, files in os.walk(dataset_path):\n","    for file in files:\n","        if file.endswith('_landmarks_with_depth.csv'):\n","            file_path = os.path.join(subdir, file)\n","\n","            # Leggi il CSV\n","            df = pd.read_csv(file_path)\n","\n","            # Ottieni il nome della cartella padre come classe\n","            gesture_class = os.path.basename(os.path.dirname(file_path))\n","\n","            # Aggiungi colonna con la classe del gesto\n","            df['class'] = gesture_class\n","\n","            all_data.append(df)\n","\n","# Unisci tutti i DataFrame in uno solo\n","final_df = pd.concat(all_data, ignore_index=True)\n","\n","# Salva in un unico CSV\n","final_df.to_csv('/content/drive/MyDrive/GRUPPO_14/dataset/landmarks_all_with_depth.csv', index=False)\n","print(\"✅ File unico creato: landmarks_all_with_depth.csv\")\n"],"metadata":{"id":"3s7ZN9hRsKm3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calcolo distanze tra landmarks"],"metadata":{"id":"ZUOeF1ZVUkIc"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import csv\n","import os\n","\n","# ----------- PARAMETRI CAMERA (come da MATLAB) ------------------\n","s = {\n","    \"principal_point\": [309.568, 245.154],\n","    \"focal_length\": [474.346, 474.346],\n","    \"distortion_coeffs\": [0.139663, 0.0914142, 0.00468509, 0.00220023, 0.0654529],\n","    \"depth_scale\": 0.000125\n","}\n","\n","# ----------- FUNZIONE: Deproiezione con correzione ottica ----------------\n","def rs2_deproject_pixel_to_point(s, pixel, depth):\n","    cx, cy = s[\"principal_point\"]\n","    fx, fy = s[\"focal_length\"]\n","    k1, k2, p1, p2, k3 = s[\"distortion_coeffs\"]\n","\n","    x = (pixel[0] - cx) / fx\n","    y = (pixel[1] - cy) / fy\n","\n","    r2 = x * x + y * y\n","    f = 1 + k1 * r2 + k2 * r2 ** 2 + k3 * r2 ** 3\n","\n","    ux = x * f + 2 * p1 * x * y + p2 * (r2 + 2 * x * x)\n","    uy = y * f + 2 * p2 * x * y + p1 * (r2 + 2 * y * y)\n","\n","    point_x = depth * ux\n","    point_y = depth * uy\n","    point_z = depth\n","\n","    return np.array([point_x, point_y, point_z])\n","\n","# ----------- FUNZIONE: Calcola distanza euclidea -------------------------\n","def dist_3D(s, pixel_start, pixel_end):\n","    \"\"\"\n","    Calcola la distanza reale 3D tra due pixel 2D con profondità z,\n","    tenendo conto delle distorsioni ottiche e della deproiezione.\n","    \"\"\"\n","    depth_units = 0.000125\n","    z1 = pixel_start[2] * depth_units\n","    z2 = pixel_end[2] * depth_units\n","\n","    p1 = rs2_deproject_pixel_to_point(s, pixel_start[:2], z1)\n","    p2 = rs2_deproject_pixel_to_point(s, pixel_end[:2], z2)\n","\n","    distance = np.sqrt(np.sum((p2 - p1) ** 2))\n","    return distance\n","\n","# ----------- COPPIE DI LANDMARK (come da immagine MediaPipe) ------------\n","landmark_pairs = [\n","    (0, 1), (1, 2), (2, 3), (3, 4), (0, 5),\n","    (5, 9), (9, 13), (13, 17),(5, 6), (6, 7),\n","    (7, 8),(9, 10), (10, 11), (11, 12),\n","    (13, 14), (14, 15), (15, 16),\n","    (17, 18), (18, 19), (19, 20)\n","]\n","\n","import numpy as np\n","import pandas as pd\n","import csv\n","\n","# ----------- PARAMETRI CAMERA (come da MATLAB) ------------------\n","s = {\n","    \"principal_point\": [309.568, 245.154],\n","    \"focal_length\": [474.346, 474.346],\n","    \"distortion_coeffs\": [0.139663, 0.0914142, 0.00468509, 0.00220023, 0.0654529],\n","    \"depth_scale\": 0.000125\n","}\n","\n","# ----------- FUNZIONE DEPROIEZIONE --------------------------------\n","def rs2_deproject_pixel_to_point(s, pixel, depth):\n","    cx, cy = s[\"principal_point\"]\n","    fx, fy = s[\"focal_length\"]\n","    k1, k2, p1, p2, k3 = s[\"distortion_coeffs\"]\n","\n","    x = (pixel[0] - cx) / fx\n","    y = (pixel[1] - cy) / fy\n","\n","    r2 = x * x + y * y\n","    f = 1 + k1 * r2 + k2 * r2**2 + k3 * r2**3\n","\n","    ux = x * f + 2 * p1 * x * y + p2 * (r2 + 2 * x * x)\n","    uy = y * f + 2 * p2 * x * y + p1 * (r2 + 2 * y * y)\n","\n","    point_x = depth * ux\n","    point_y = depth * uy\n","    point_z = depth\n","\n","    return np.array([point_x, point_y, point_z])\n","\n","# ----------- FUNZIONE DISTANZA 3D --------------------------\n","def dist_3D(s, pixel_start, pixel_end):\n","    z1 = pixel_start[2] * s[\"depth_scale\"]\n","    z2 = pixel_end[2] * s[\"depth_scale\"]\n","    p1 = rs2_deproject_pixel_to_point(s, pixel_start[:2], z1)\n","    p2 = rs2_deproject_pixel_to_point(s, pixel_end[:2], z2)\n","    return np.linalg.norm(p2 - p1)\n","\n","# ----------- NOMI LANDMARK MEDIAPIPE -------------------------------\n","landmark_names = [\n","    \"WRIST\", \"THUMB_CMC\", \"THUMB_MCP\", \"THUMB_IP\", \"THUMB_TIP\",\n","    \"INDEX_MCP\", \"INDEX_PIP\", \"INDEX_DIP\", \"INDEX_TIP\",\n","    \"MIDDLE_MCP\", \"MIDDLE_PIP\", \"MIDDLE_DIP\", \"MIDDLE_TIP\",\n","    \"RING_MCP\", \"RING_PIP\", \"RING_DIP\", \"RING_TIP\",\n","    \"PINKY_MCP\", \"PINKY_PIP\", \"PINKY_DIP\", \"PINKY_TIP\"\n","]\n","\n","landmark_pairs = [\n","    (0, 1), (1, 2), (2, 3), (3, 4), (0, 5),\n","    (5, 9), (9, 13), (13, 17),\n","    (5, 6), (6, 7), (7, 8),\n","    (9, 10), (10, 11), (11, 12),\n","    (13, 14), (14, 15), (15, 16),\n","    (17, 18), (18, 19), (19, 20)\n","]\n","\n","# ----------- CARICAMENTO CSV DEI LANDMARK -------------------------\n","csv_path = '/content/drive/MyDrive/GRUPPO_14/dataset/landmarks_all_with_depth.csv'\n","all_data = pd.read_csv(csv_path)\n","num_landmarks = 21\n","num_frames = len(all_data) // num_landmarks\n","\n","# ----------- CREA CSV UNICO PER TUTTI I FRAME ---------------------\n","out_path = '/content/drive/MyDrive/GRUPPO_14/dataset/distanze_tutti_i_frame.csv'\n","with open(out_path, \"w\", newline=\"\") as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow([\"frame_id\", \"pair\", \"distance_cm\"])  # intestazione\n","\n","    for frame_id in range(num_frames):\n","        frame_data = all_data.iloc[frame_id * num_landmarks : (frame_id + 1) * num_landmarks]\n","        landmarks = frame_data[[\"x_pixel\", \"y_pixel\", \"z_depth\"]].values  # shape: (21, 3)\n","\n","        for i, j in landmark_pairs:\n","            name_i = landmark_names[i]\n","            name_j = landmark_names[j]\n","            d = dist_3D(s, landmarks[i], landmarks[j]) * 100  # in cm\n","            writer.writerow([frame_id, f\"{name_i}_{name_j}\", d])\n","\n","print(f\"Tutte le distanze sono state salvate in '{out_path}'\")"],"metadata":{"id":"8S8uPfvDUfhh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["COSTRUZIONE DATASET FINALE (FEATURES + CLASSE)"],"metadata":{"id":"zDEWxzWCaIkc"}},{"cell_type":"code","source":["import pandas as pd\n","\n","#  1. Carica il file delle distanze 3D\n","df_dist = pd.read_csv('/content/drive/MyDrive/GRUPPO_14/dataset/distanze_tutti_i_frame.csv')\n","\n","#  2. Carica il file dei landmark con la classe\n","df_landmarks = pd.read_csv('/content/drive/MyDrive/GRUPPO_14/dataset/landmarks_all_with_depth.csv')\n","\n","# Calcola il numero di frame = ogni 21 righe è un frame\n","num_landmarks = 21\n","num_frames = len(df_landmarks) // num_landmarks\n","\n","# Estrai la classe per ogni frame (usando ogni 21 righe)\n","class_per_frame = df_landmarks['class'][::num_landmarks].reset_index(drop=True)\n","\n","# Crea un DataFrame con mapping frame_id → class\n","frame_class_df = pd.DataFrame({\n","    'frame_id': range(num_frames),\n","    'class': class_per_frame\n","})\n","\n","# 3. Riorganizza le distanze: ogni riga = 1 frame, ogni colonna = 1 coppia landmark\n","pivot_df = df_dist.pivot(index='frame_id', columns='pair', values='distance_cm')\n","pivot_df = pivot_df.reindex(sorted(pivot_df.columns), axis=1)  # ordina colonne alfabeticamente\n","\n","# 4. Aggiungi la classe\n","pivot_df = pivot_df.merge(frame_class_df, on='frame_id')\n","\n","#  5. Salva il file aggregato\n","pivot_df.to_csv('/content/drive/MyDrive/GRUPPO_14/dataset/distanze_aggregated_con_classe.csv', index=False)\n","print(\"File salvato: distanze_aggregated_con_classe.csv\")\n"],"metadata":{"id":"agHGw8LiaFiv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Suddivisione Dataset"],"metadata":{"id":"MJtStQUWC6GA"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","import random\n","\n","# Prepara le feature (X) e i target (y)\n","dataset = pd.read_csv('./distanze_aggregated_con_classe.csv')\n","dataset = dataset.drop(['frame_id'], axis=1)\n","\n","# print the amount of 0 values in the features\n","print(f\"Amount of 0 values in the features: {((dataset == 0).sum()).sum()}\")\n","\n","X = dataset.drop(['class'], axis=1)  # Tutte le colonne tranne la classe\n","\n","y = dataset['class']                 # Colonna target\n","\n","# Normalizzazione dei dati\n","scaler = StandardScaler() # Standardizzazione z-score\n","X_scaled = scaler.fit_transform(X)\n","\n","# Divisione dataset in construction e test set\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n","\n","import os\n","\n","# Percorso base\n","base_path = '/content/drive/MyDrive/GRUPPO_14/dataset'\n","\n","# Crea le cartelle se non esistono\n","for folder in ['training', 'validation', 'test']:\n","    os.makedirs(os.path.join(base_path, folder), exist_ok=True)\n","\n","# Ricostruisci i DataFrame con le classi\n","train_df = pd.DataFrame(X_train, columns=[f'feat{i}' for i in range(X_train.shape[1])])\n","train_df['class'] = y_train.reset_index(drop=True)\n","\n","test_df = pd.DataFrame(X_test, columns=[f'feat{i}' for i in range(X_test.shape[1])])\n","test_df['class'] = y_test.reset_index(drop=True)\n","\n","# Salva i file CSV\n","train_df.to_csv(os.path.join(base_path, 'training', 'train.csv'), index=False)\n","test_df.to_csv(os.path.join(base_path, 'test', 'test.csv'), index=False)\n","\n","print(\"Dataset salvato in: training/train.csv, test/test.csv\")\n"],"metadata":{"id":"iVb6_uaC2_5V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Shape X_train:\", X_train.shape)\n","print(\"Shape X_test:\", X_test.shape)"],"metadata":{"id":"ORMcM6eoZSny"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# count the amount of samples for each class\n","\n","print(y.value_counts())"],"metadata":{"id":"sZmqPH4YNpVY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualizzazione RGB+Landmarks"],"metadata":{"id":"bQawG62MKkh_"}},{"cell_type":"code","source":["img_path = \"/content/drive/MyDrive/GRUPPO_14/dataset/1/ALESSANDRA_1D_Color.png\"\n","csv_path = \"/content/drive/MyDrive/GRUPPO_14/dataset/1/ALESSANDRA_1D_Color_landmarks.csv\"\n","\n","def salva_landmark_con_connessioni(img_path, csv_path, output_path):\n","    import cv2\n","    import pandas as pd\n","    import matplotlib.pyplot as plt\n","\n","    landmark_pairs = [\n","        (0, 1), (1, 2), (2, 3), (3, 4), (0, 5),\n","        (5, 9), (9, 13), (13, 17), (5, 6), (6, 7),\n","        (7, 8), (9, 10), (10, 11), (11, 12),\n","        (13, 14), (14, 15), (15, 16),\n","        (17, 18), (18, 19), (19, 20), (0, 17)\n","    ]\n","\n","    img = cv2.imread(img_path)\n","    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    df = pd.read_csv(csv_path)\n","\n","    fig, ax = plt.subplots(figsize=(6, 6))\n","    ax.imshow(img_rgb)\n","    ax.axis('off')\n","\n","    for _, row in df.iterrows():\n","        x = row['x_pixel']\n","        y = row['y_pixel']\n","        ax.plot(x, y, 'ro', markersize=4)\n","\n","    for i, j in landmark_pairs:\n","        point_i = df[df['id'] == i]\n","        point_j = df[df['id'] == j]\n","        if not point_i.empty and not point_j.empty:\n","            xi, yi = point_i.iloc[0]['x_pixel'], point_i.iloc[0]['y_pixel']\n","            xj, yj = point_j.iloc[0]['x_pixel'], point_j.iloc[0]['y_pixel']\n","            ax.plot([xi, xj], [yi, yj], color='yellow', linewidth=1.5)\n","\n","    fig.savefig(output_path, bbox_inches='tight')\n","    plt.close(fig)\n","    print(f\"Immagine salvata in: {output_path}\")\n","\n","img1_path = \"/content/drive/MyDrive/GRUPPO_14/dataset/1/ALESSANDRA_1D_Color.png\"\n","csv1_path = \"/content/drive/MyDrive/GRUPPO_14/dataset/1/ALESSANDRA_1D_Color_landmarks.csv\"\n","\n","img2_path = \"/content/drive/MyDrive/GRUPPO_14/dataset/2/ALESSANDRA_1D_Color.png\"\n","csv2_path = \"/content/drive/MyDrive/GRUPPO_14/dataset/2/ALESSANDRA_1D_Color_landmarks.csv\"\n","\n","img3_path = \"/content/drive/MyDrive/GRUPPO_14/dataset/3/ALESSANDRA_1D_Color.png\"\n","csv3_path = \"/content/drive/MyDrive/GRUPPO_14/dataset/3/ALESSANDRA_1D_Color_landmarks.csv\"\n","\n","img4_path = \"/content/drive/MyDrive/GRUPPO_14/dataset/4/ALESSANDRA_1D_Color.png\"\n","csv4_path = \"/content/drive/MyDrive/GRUPPO_14/dataset/4/ALESSANDRA_1D_Color_landmarks.csv\"\n","\n","salva_landmark_con_connessioni(img1_path, csv1_path, \"/content/drive/MyDrive/GRUPPO_14/gesto1.png\")\n","salva_landmark_con_connessioni(img2_path, csv2_path, \"/content/drive/MyDrive/GRUPPO_14/gesto2.png\")\n","salva_landmark_con_connessioni(img3_path, csv3_path, \"/content/drive/MyDrive/GRUPPO_14/gesto3.png\")\n","salva_landmark_con_connessioni(img4_path, csv4_path, \"/content/drive/MyDrive/GRUPPO_14/gesto4.png\")"],"metadata":{"id":"ZoM4KLYzKkOd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Valutazione riduzione dimensionale"],"metadata":{"id":"YkCqxsGz8lSd"}},{"cell_type":"code","source":["# reduce dimensionality by applying PCA\n","from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","\n","pca = PCA(n_components=0.95)\n","X_train_pca = pca.fit_transform(X_train)\n","X_test_pca = pca.transform(X_test)\n","\n","print(\"Shape X_train_pca:\", X_train_pca.shape)\n","print(\"Shape X_test_pca:\", X_test_pca.shape)"],"metadata":{"id":"d1loawxOeXJ-"},"execution_count":null,"outputs":[]}]}